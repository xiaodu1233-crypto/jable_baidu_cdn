import asyncio
import pathlib
import re
import subprocess
import time
from zoneinfo import reset_tzpath
import glob
import aiohttp
import os
# from aiofiles import open
from aiohttp import ClientTimeout

# --- é…ç½®åŒº ---
BOT_TOKEN = '8462879327:AAGzeC1ydXRaMN-4sog7ebFtL4zSoOGE5Es'
CHAT_ID = '6554928796'
WORKER_URL = 'https://tele.xiaodu1234.xyz'
MAX_CONCURRENT_TASKS = 3  # é™åˆ¶åŒæ—¶ä¸Šä¼ çš„æ–‡ä»¶æ•°é‡ï¼Œå»ºè®® 2-5 ä¹‹é—´

LOCAL_PROXY = "http://127.0.0.1:10808"

index = 0
class TelegramUploader:
    def __init__(self, token, chat_id, worker_url, max_tasks):
        self.api_url = f"https://api.telegram.org/bot{token}"
        self.chat_id = chat_id
        self.worker_url = worker_url
        # æ ¸å¿ƒï¼šä¿¡å·é‡ï¼Œç”¨äºæ§åˆ¶å¹¶å‘


        # è‡ªåŠ¨åˆ¤æ–­ç¯å¢ƒï¼šå¦‚æœåœ¨ GitHub Actions è¿è¡Œï¼Œåˆ™ä¸ä½¿ç”¨ä»£ç†
        if os.getenv('GITHUB_ACTIONS') == 'true':
            self.proxy = None
            self.semaphore = asyncio.Semaphore(5)
            print("ğŸš€ æ£€æµ‹åˆ°è¿è¡Œç¯å¢ƒï¼šGitHub Actions (ä¸ä½¿ç”¨ä»£ç†)")
        else:
            self.proxy = LOCAL_PROXY
            self.semaphore = asyncio.Semaphore(max_tasks)
            print(f"ğŸ  æ£€æµ‹åˆ°è¿è¡Œç¯å¢ƒï¼šæœ¬åœ° (ä½¿ç”¨ä»£ç†: {self.proxy})")

    async def upload_single_file(self, session, file_path):
        global index
        """å¸¦å¹¶å‘æ§åˆ¶çš„ä¸Šä¼ ä»»åŠ¡"""
        async with self.semaphore:  # åªæœ‰æ‹¿åˆ°â€œè®¸å¯è¯â€çš„ä»»åŠ¡æ‰èƒ½ç»§ç»­
            url = f"{self.api_url}/sendDocument"

            data = aiohttp.FormData()
            data.add_field('chat_id', str(self.chat_id))
            data.add_field('document', open(file_path, 'rb'), filename=os.path.basename(file_path))

            try:
                # æ¨¡æ‹Ÿä¸€ç‚¹å¾®å°çš„é—´éš”ï¼Œé˜²æ­¢ç¬æ—¶å¹¶å‘è¿‡é«˜
                await asyncio.sleep(0.1)


                async with session.post(url, data=data, proxy= self.proxy) as response:
                    result = await response.json()

                    if response.status == 429:  # è§¦å‘ Telegram é™é€Ÿ
                        retry_after = result.get('parameters', {}).get('retry_after', 10)
                        print(f"âš ï¸ è¢«é™é€Ÿäº†ï¼éœ€ç­‰å¾… {retry_after} ç§’")
                        return None

                    if result.get('ok'):
                        print(result)
                        file_id = result['result']['document']['file_id']
                        file_name2 = result['result']['document']['file_name']
                        permanent_link = f"{self.worker_url}/?file_id={file_id}"
                        print(f"âœ… æˆåŠŸ: {os.path.basename(file_path)}")
                        index = index + 1
                        await asyncio.sleep(1)
                        print(f'å½“å‰ä¸‹è½½äº† {index}')
                        return file_name2, permanent_link,
                    else:
                        print(f"âŒ å¤±è´¥: {os.path.basename(file_path)} - {result.get('description')}")
                        return None
            except Exception as e:
                print(f"--- âš ï¸ é”™è¯¯: {e}")
                return None

    async def upload_batch(self, file_paths):
        timeout = ClientTimeout(total=300, connect=30)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            tasks = [self.upload_single_file(session, fp) for fp in file_paths]
            return await asyncio.gather(*tasks)


async def generate_m3u8(file_list, duration=10, output_file=''):
    """
    file_list: åŒ…å« (æ–‡ä»¶å, URL) çš„å…ƒç»„åˆ—è¡¨
    """

    # --- æ ¸å¿ƒï¼šè‡ªç„¶æ’åº (Natural Sort) ---
    # ä½¿ç”¨æ­£åˆ™æå–æ–‡ä»¶åä¸­çš„æ•°å­—è¿›è¡Œæ’åºï¼Œé˜²æ­¢ "part10.ts" æ’åœ¨ "part2.ts" å‰é¢
    def natural_key(string_):
        return [int(s) if s.isdigit() else s.lower() for s in re.split(r'(\d+)', string_[0])]

    # æŒ‰ç…§æ–‡ä»¶åè¿›è¡Œè‡ªç„¶æ’åº
    sorted_list = sorted(file_list, key=natural_key)

    m3u8_lines = [
        "#EXTM3U",
        "#EXT-X-VERSION:3",
        f"#EXT-X-TARGETDURATION:{duration + 2}",  # é€šå¸¸æ¯”å®é™…æ—¶é•¿å¤šä¸€ç‚¹
        "#EXT-X-MEDIA-SEQUENCE:0",
    ]

    for file_name, file_url in sorted_list:
        m3u8_lines.append(f"#EXTINF:{duration}.0,")
        m3u8_lines.append(file_url)

    m3u8_lines.append("#EXT-X-ENDLIST")

    with open(output_file, "w") as f:
        f.write("\n".join(m3u8_lines))


# --- æ‰§è¡ŒåŒº ---
async def main(my_files, file_name):
    # å‡è®¾ä½ æœ‰ 100 ä¸ªæ–‡ä»¶ï¼Œç¨‹åºç°åœ¨ä¹Ÿä¼šæœ‰åºåœ° 3 ä¸ª 3 ä¸ªåœ°ä¼ 

    # return
    uploader = TelegramUploader(BOT_TOKEN, CHAT_ID, WORKER_URL, MAX_CONCURRENT_TASKS)
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¸Šä¼ ï¼Œå½“å‰å¹¶å‘é™åˆ¶: {MAX_CONCURRENT_TASKS}")

    print(my_files)
    # return

    links = await uploader.upload_batch(my_files)
    links = [l for l in links if l]
    print(f"\nâœ¨ å®Œæˆï¼æˆåŠŸè·å– {len([l for l in links if l])} ä¸ªé“¾æ¥ã€‚")
    print(links)
    await generate_m3u8(links, output_file = file_name)
    final_m3u8_id = await uploader.upload_single_file(aiohttp.ClientSession(), file_name)
    print(f"ğŸ¬ ä½ çš„åœ¨çº¿æ’­æ”¾åœ°å€: {final_m3u8_id[1]}")


def merge_and_resplit(ts_dir, output_mp4="merged.mp4", segment_time = 130):
    # 1. è·å–å¹¶è‡ªç„¶æ’åº
    files = glob.glob(os.path.join(ts_dir, "*.ts"))
    files.sort(key=lambda f: int(re.search(r'\d+', os.path.basename(f)).group()))

    if not files:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°åˆ†ç‰‡")
        return

    # 2. ç»•è¿‡ FFmpeg Concatï¼Œä½¿ç”¨ Linux cat äºŒè¿›åˆ¶åˆå¹¶
    # è¿™ç§æ–¹å¼å¯¹ 1000+ åˆ†ç‰‡éå¸¸å‹å¥½ï¼Œä¸ä¼šæº¢å‡º
    combined_ts = "combined_all.ts"
    print(f"ğŸ”— æ­£åœ¨ä½¿ç”¨äºŒè¿›åˆ¶æµåˆå¹¶ {len(files)} ä¸ªåˆ†ç‰‡...")

    # æ„é€  cat å‘½ä»¤ï¼šcat file1.ts file2.ts ... > combined_all.ts
    # å¦‚æœæ–‡ä»¶å¤ªå¤šå¯¼è‡´å‘½ä»¤è¡Œé•¿åº¦è¶…é™ï¼Œæˆ‘ä»¬åˆ†æ‰¹å†™å…¥
    with open(combined_ts, 'wb') as outfile:
        for filename in files:
            with open(filename, 'rb') as infile:
                outfile.write(infile.read())

        # 3. æŒ‰æ—¶é—´é‡æ–°åˆ‡ç‰‡
        print(f"âœ‚ï¸ æ­£åœ¨æŒ‰æ—¶é—´ï¼ˆ{segment_time}sï¼‰è¿›è¡ŒäºŒæ¬¡åˆ‡ç‰‡...")
        split_cmd = [
            "ffmpeg", "-y",
            "-i", combined_ts,  # è¾“å…¥åˆå¹¶åçš„ TS
            "-c", "copy",  # æ— æŸæ‹·è´
            "-map", "0",
            "-f", "segment",
            "-segment_time", str(segment_time),  # ã€æ­¤å¤„å·²æ¢å›æ—¶é—´å‚æ•°ã€‘
            "-reset_timestamps", "1",
            "upload_%03d.ts"  # ç”Ÿæˆæ–°çš„ä¸Šä¼ ç‰‡æ®µ
        ]
    try:
        subprocess.run(split_cmd, check=True)
        print("âœ… æˆåŠŸç”Ÿæˆ 45MB è§„èŒƒåˆ‡ç‰‡")
    finally:
        # æ¸…ç†é‚£ä¸ªå·¨å¤§çš„ä¸´æ—¶åˆå¹¶æ–‡ä»¶
        if os.path.exists(combined_ts):
            os.remove(combined_ts)


# è°ƒç”¨ç¤ºä¾‹


def split_video_by_time(input_file , segment_time=130):

    """
    ä½¿ç”¨ FFmpeg å°†è§†é¢‘æŒ‰æ—¶é—´åˆ‡å‰²ä¸º TS ç‰‡æ®µ
    :param input_file: è¾“å…¥è§†é¢‘è·¯å¾„ (å¦‚ 'movie.mp4')
    :param segment_time: æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå»ºè®® 120-150s å¯¹åº” 50MB å·¦å³
    """
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åæ ¼å¼ï¼Œä¾‹å¦‚ out000.ts, out001.ts
    path = "."
    files_and_dirs = os.listdir(path)

    for item in files_and_dirs:
        if item.startswith('ok'):
            print(pathlib.Path(item).is_dir())
        print(item)

    path = pathlib.Path(input_file)
    if path.is_dir():
        print("ç›®å½•")
        for item in path.iterdir():
            if item.is_dir():
                merge_and_resplit(item)
                break
    else:
        print("æ–‡ä»¶")



if __name__ == "__main__":
    urtl = 'https://gmas-clena.mushroomtrack.com/hls/QkTlFjb1nCtDBjWNsIbkQg/1768049370/35000/35652/35652.m3u8'
    # urtl = 'https://kumak-clonser.mushroomtrack.com/hls/PFzMIjWSX16Psbsa2N1tHw/1768043344/48000/48168/48168.m3u8'
    save_name = 'ok'
    link_name = 'N_m3u8DL-RE'
    if os.getenv('GITHUB_ACTIONS') == 'true':
        link_name = './N_m3u8DL-RE'


    # "--tmp-dir", "./temp",  # ä¸´æ—¶ç›®å½•å­˜ TS ç‰‡æ®µ
    # "--del-after-done", "true",

    command = [
        link_name,
        urtl,
        "--save-name", "ok",
        "--check-segments-count", "false"
    ]
    subprocess.run(command)

    time.sleep(2)

    split_video_by_time(save_name)

    path = pathlib.Path(save_name)
    file_name = 'finish.m3u8'
    print(f'file_name, {file_name}')

    time.sleep(2)

    #
    my_files = []
    for item in path.joinpath('0____').glob('*.ts'):
        my_files.append(item)
    if len(my_files):
        asyncio.run(main(my_files, file_name))